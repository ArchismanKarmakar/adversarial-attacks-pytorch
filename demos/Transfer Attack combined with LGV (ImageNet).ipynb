{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Transfer Attack combined with LGV (ImageNet).ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demo - LGV Transfer Attacks (ImageNet)\n",
    "\n",
    "This notebook demonstrates the LGV technique from the **ECCV22** paper [\"LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity\"](https://arxiv.org/abs/2207.13129) by Martin Gubri, Maxime Cordy, Mike Papadakis, Yves Le Traon from the University of Luxembourg and Koushik Sen from University of California, Berkeley.\n",
    "\n",
    "LGV can be combined with several attacks to improve the transferability of adversarial examples. \n",
    "\n",
    "1. First, LGV collects models along the SGD trajectory with a high learning rate.  The following figure illustrates the approach. In this notebook, we use publically available pretrained models from the original paper. Nevertheless, commented code below is available to collect new models in 10 epochs.\n",
    "\n",
    "![](https://github.com/Framartin/lgv-geometric-transferability/raw/main/lgv/plots/diagram_lr.png?raw=true)\n",
    "\n",
    "2. Second, we apply a standard `torchattacks` attack on one LGV model per iteration. This step does not require any modification of the existing attack, as shown below. Once the models are collected, attacking does not increase the computation cost because we attack a single model per iteration. Computing each iteration gradient on all models gives generally better results, at the expense of an increase in computations.\n",
    "\n",
    "## 1. Installation"
   ],
   "metadata": {
    "id": "-smvfVCPl43G"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WXv80XDDichl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4feb2675-716b-4044-a3b1-280aef17d323"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchattacks tqdm"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchattacks import LGV, BIM, MIFGSM, DIFGSM, TIFGSM"
   ],
   "metadata": {
    "id": "7K39VJKilo0A"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Download LGV models from the original paper. The zip file includes 3 sets of LGV collected models, corresponding to 3 random seeds starting from 3 independently trained DNNs. We will use a single one here, but you may want to report mean and standard deviation computed across several random seeds."
   ],
   "metadata": {
    "id": "tAvgCk-poMO-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!wget -O lgv_models.zip https://figshare.com/ndownloader/files/36698862\n",
    "!unzip lgv_models.zip"
   ],
   "metadata": {
    "id": "y2V2gNoWo5nq",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e0346718-74b1-4836-ff64-545ecfe450ca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2022-08-18 14:46:28--  https://figshare.com/ndownloader/files/36698862\n",
      "Resolving figshare.com (figshare.com)... 52.49.60.170, 52.30.212.171, 2a05:d018:1f4:d003:5e66:753c:3d81:88f7, ...\n",
      "Connecting to figshare.com (figshare.com)|52.49.60.170|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/36698862/models.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20220818/eu-west-1/s3/aws4_request&X-Amz-Date=20220818T144629Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2c3903f1bd12bf7d80950c8b9428d7b932ac51a027caf322a2661f71a170e768 [following]\n",
      "--2022-08-18 14:46:29--  https://s3-eu-west-1.amazonaws.com/pfigshare-u-files/36698862/models.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIYCQYOYV5JSSROOA/20220818/eu-west-1/s3/aws4_request&X-Amz-Date=20220818T144629Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2c3903f1bd12bf7d80950c8b9428d7b932ac51a027caf322a2661f71a170e768\n",
      "Resolving s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)... 52.92.0.168\n",
      "Connecting to s3-eu-west-1.amazonaws.com (s3-eu-west-1.amazonaws.com)|52.92.0.168|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12001708922 (11G) [application/zip]\n",
      "Saving to: ‘lgv_models.zip’\n",
      "\n",
      "lgv_models.zip      100%[===================>]  11.18G  13.6MB/s    in 14m 24s \n",
      "\n",
      "2022-08-18 15:00:54 (13.2 MB/s) - ‘lgv_models.zip’ saved [12001708922/12001708922]\n",
      "\n",
      "Archive:  lgv_models.zip\n",
      "   creating: models/\n",
      "   creating: models/ImageNet/\n",
      "   creating: models/ImageNet/resnet50/\n",
      "   creating: models/ImageNet/resnet50/cSGD/\n",
      "   creating: models/ImageNet/resnet50/cSGD/seed0/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00001.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00002.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00003.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00004.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00005.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00006.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00007.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00008.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00009.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00010.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00011.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00012.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00013.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00014.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00015.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00016.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00017.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00018.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00019.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00020.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00021.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00022.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00023.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00024.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00025.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00026.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00027.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00028.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00029.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00030.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00031.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00032.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00033.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00034.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00035.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00036.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00037.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00038.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00039.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/iter-00040.pt  \n",
      "   creating: models/ImageNet/resnet50/cSGD/seed0/original/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed0/original/ImageNet-ResNet50-052e7f78e4db--1564492444-1.pth.tar  \n",
      "   creating: models/ImageNet/resnet50/cSGD/seed1/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00001.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00002.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00003.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00004.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00005.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00006.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00007.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00008.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00009.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00010.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00011.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00012.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00013.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00014.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00015.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00016.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00017.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00018.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00019.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00020.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00021.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00022.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00023.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00024.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00025.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00026.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00027.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00028.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00029.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00030.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00031.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00032.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00033.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00034.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00035.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00036.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00037.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00038.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00039.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/iter-00040.pt  \n",
      "   creating: models/ImageNet/resnet50/cSGD/seed1/original/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed1/original/ImageNet-ResNet50-1132c260ef75--1564493784-1.pth.tar  \n",
      "   creating: models/ImageNet/resnet50/cSGD/seed2/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00001.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00002.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00003.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00004.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00005.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00006.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00007.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00008.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00009.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00010.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00011.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00012.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00013.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00014.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00015.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00016.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00017.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00018.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00019.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00020.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00021.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00022.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00023.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00024.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00025.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00026.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00027.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00028.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00029.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00030.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00031.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00032.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00033.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00034.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00035.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00036.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00037.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00038.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00039.pt  \n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/iter-00040.pt  \n",
      "   creating: models/ImageNet/resnet50/cSGD/seed2/original/\n",
      "  inflating: models/ImageNet/resnet50/cSGD/seed2/original/ImageNet-ResNet50-2f817072e8da--1564493734-1.pth.tar  \n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up some constants."
   ],
   "metadata": {
    "id": "oZV-VQaLnvYh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH_LGV_MODELS=\"models/ImageNet/resnet50/cSGD/seed0\"\n",
    "DATA_PATH=\"/content/drive/MyDrive/data/ILSVRC2012_samples\"\n",
    "BATCH_SIZE_TRAIN=256  # changing batch-size to collect models might require you to tune the LGV learning rate hyperparameter\n",
    "BATCH_SIZE_TEST=64\n",
    "N_WORKERS=5\n",
    "N_EXAMPLES=500  # increase to at least 1K if you want to publish results"
   ],
   "metadata": {
    "id": "cwPsBMBolukV"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ],
   "metadata": {
    "id": "intaGyw8a_2A"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load models\n",
    "\n",
    "We load the surrogate and target models. \n"
   ],
   "metadata": {
    "id": "sUamZSc2Mtcr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def add_normalization_layer(model, mean, std):\n",
    "    \"\"\"\n",
    "    Add a data normalization layer to a model\n",
    "    \"\"\"\n",
    "    return torch.nn.Sequential(\n",
    "        transforms.Normalize(mean=mean, std=std),\n",
    "        model\n",
    "    )"
   ],
   "metadata": {
    "id": "aOHfLJthNQFM"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the LGV collected models."
   ],
   "metadata": {
    "id": "raQ2Osv7Nt2-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# LGV surrogate\n",
    "paths_models = glob.glob(f'{PATH_LGV_MODELS}/*.pt')\n",
    "paths_models = sorted(paths_models)\n",
    "list_models = []\n",
    "for path in paths_models:\n",
    "    model = resnet50()\n",
    "    model.load_state_dict(torch.load(path)['state_dict'])\n",
    "    model = add_normalization_layer(model=model, \n",
    "                                    mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "    model = model.eval().cuda()\n",
    "    list_models.append(model)"
   ],
   "metadata": {
    "id": "VM0e7uWYNIQr"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(list_models)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_T6rqld-VFmX",
    "outputId": "ec9bd83d-f3f3-48cd-8ae6-0b584dc2b344"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the original DNN from which model collection started."
   ],
   "metadata": {
    "id": "3ITm7WBuNzwi"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "base_model = resnet50()\n",
    "ckpt = torch.load(f'{PATH_LGV_MODELS}/original/ImageNet-ResNet50-052e7f78e4db--1564492444-1.pth.tar')['state_dict']\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in ckpt.items():\n",
    "    name = k[7:]  # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "base_model.load_state_dict(new_state_dict)\n",
    "base_model = add_normalization_layer(model=base_model,\n",
    "                                     mean=[0.485, 0.456, 0.406], \n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "base_model = base_model.eval().cuda()\n"
   ],
   "metadata": {
    "id": "fG4i9Sg5NzN4"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we load the target model, the pretrained resnet50 model provided by torchvision."
   ],
   "metadata": {
    "id": "dWOITIe6OQiw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "target_model = resnet50(pretrained=True)\n",
    "target_model = add_normalization_layer(model=target_model, \n",
    "                                       mean=[0.485, 0.456, 0.406], \n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "target_model = target_model.eval().cuda()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZInjHVgOZsa",
    "outputId": "a0c476d0-9e72-4444-a3e0-a32fa01360e1"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataloader\n",
    "\n",
    "Loaders should load unnormalized data (in [0,1]). Here, the test loader is a random subset of 2K test examples. "
   ],
   "metadata": {
    "id": "2kxpmNbnOpgQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "traindir = os.path.join(DATA_PATH, 'train')\n",
    "transform_train = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "trainset = datasets.ImageFolder(traindir, transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE_TRAIN,\n",
    "                                          shuffle=True, num_workers=N_WORKERS,\n",
    "                                          pin_memory=True)\n",
    "testdir = os.path.join(DATA_PATH, 'validation')\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "testset = datasets.ImageFolder(testdir, transform_test)\n",
    "indices = torch.from_numpy(np.random.choice(len(testset), size=(N_EXAMPLES,),\n",
    "                                            replace=False))\n",
    "# select a subset of 500 examples. The original paper selects only original \n",
    "# examples that are correctly predicted by the target model, which might explain\n",
    "# why we obtain slightly different results.\n",
    "\n",
    "testsubset = torch.utils.data.Subset(trainset, indices)\n",
    "testloader = torch.utils.data.DataLoader(testsubset, batch_size=BATCH_SIZE_TEST,\n",
    "                                         shuffle=False, num_workers=N_WORKERS,\n",
    "                                         pin_memory=False)"
   ],
   "metadata": {
    "id": "mcmyJbq1OvO5"
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attacks\n",
    "\n",
    "We can easily combine LGV with attacks available out-of-the-box in `torchattacks`. Then, we report the success rates of the vanilla attacks."
   ],
   "metadata": {
    "id": "zoiI9zBsO-sp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def report_success_rate(atk):\n",
    "    \"\"\"\n",
    "    Compute the success rate of the provided attack on test images\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(testloader):\n",
    "        images = images.cuda()\n",
    "        with torch.no_grad():\n",
    "            outputs = target_model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "        adv_images = atk(images, predicted)\n",
    "        with torch.no_grad():\n",
    "            outputs_adv = target_model(adv_images)\n",
    "            _, predicted_adv = torch.max(outputs_adv.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted_adv == predicted).sum()\n",
    "    print(f\"Success rate of {type(atk).__name__}{'-'+atk.attack_class.__name__ if hasattr(atk, 'attack_class') else ''}: {100 - 100 * float(correct) / total}%\\n\")\n"
   ],
   "metadata": {
    "id": "OaX72F8fPjm6"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LGV + BIM\n",
    "\n",
    "The most classical is to use LGV on top of BIM. \n",
    "\n",
    "- Below we provide commented code to collect the models yourself if you would rather not use the pretrained collected models. Collecting new models leads to similar results.\n",
    "- Ideally, you want the number of attack iterations to be greater or equal than the number of collected models (`epochs * nb_models_epoch`). Otherwise, consider increasing `n_grad`, the number of models to ensemble at each iteration (please see the last section of the notebook). As shown in the paper, 50 BIM iterations have higher success rate than 10 BIM iterations.\n",
    "- Changing the surrogate architecture or the training batch-size may require you to tune the learning rate (`lr`) hyperparameter. Preliminary experiments suggested that `lr=0.1` might be slightly better than the default 0.05 for some architectures.\n",
    "- If you are limited in computations or memory, consider reducing the number of epochs to 5 and the number of models per epoch to 2. It should not impact too much the success rates (cf. appendix of the original paper)."
   ],
   "metadata": {
    "id": "-GwSJI-OP259"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, \n",
    "          wd=1e-4, attack_class=BIM, eps=4/255, alpha=4/255/10,\n",
    "          steps=50, verbose=True)\n",
    "atk.load_models(list_models)  # load our list of collected models\n",
    "\n",
    "# uncomment the next 2 lines and comment the last one to collect models yourself (10 ImageNet epochs)\n",
    "#atk.collect_models()\n",
    "#atk.save_models('models/lgv')\n",
    "\n",
    "report_success_rate(atk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8750gjBP0lU",
    "outputId": "306ced86-12de-45ee-fab9-9b658b933b08"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Phase 2: craft adversarial examples with BIM\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [03:59<00:00, 29.96s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-BIM: 98.2%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LGV with other attacks\n",
    "\n",
    "LGV can be easily combined with other attacks provided by `torchattacks`. By default, LGV compute the gradient of a single model at each iteration (`n_grad=1`). The parameter `n_grad` should be set to `-1` for single-step attacks, such as `FGSM`, to compute its unique gradient against all available models."
   ],
   "metadata": {
    "id": "dHvCPWNdRTJ0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have collected models yourself (using `LGV.collect_models()`), you may want to load the saved models to the new `LGV` instance as below:"
   ],
   "metadata": {
    "id": "v-2fw-REez10"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#paths_models = glob.glob('models/lgv/*.pt')\n",
    "#paths_models.sort()\n",
    "#list_models = []\n",
    "#for path in paths_models:\n",
    "#  model = resnet50()\n",
    "#  model.load_state_dict(torch.load(path)['state_dict'])\n",
    "#  model = add_normalization_layer(model=model, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#  model = model.eval().cuda()\n",
    "#  list_models.append(model)"
   ],
   "metadata": {
    "id": "h4m29Pg-ezIA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We evaluate LGV when combined with more advanced attacks than BIM."
   ],
   "metadata": {
    "id": "7tFeND9hfsaW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"LGV+MI\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, wd=1e-4, attack_class=MIFGSM, eps=4/255, alpha=4/255/10, steps=50, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"LGV+DI\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, wd=1e-4, attack_class=DIFGSM, eps=4/255, alpha=4/255/10, steps=50, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"LGV+DI+MI\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, wd=1e-4, attack_class=DIFGSM, eps=4/255, alpha=4/255/10, steps=50, decay=1.0, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"LGV+TI\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, wd=1e-4, attack_class=TIFGSM, eps=4/255, alpha=4/255/10, steps=50, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"LGV+TI+MI\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, wd=1e-4, attack_class=TIFGSM, eps=4/255, alpha=4/255/10, steps=50, decay=1.0, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hrDQTlblRcEk",
    "outputId": "cb6d5b31-d14f-4568-aa49-e56c238e4407"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LGV+MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.13s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-MIFGSM: 98.8%\n",
      "LGV+DI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.15s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-DIFGSM: 98.4%\n",
      "LGV+DI+MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.16s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-DIFGSM: 98.6%\n",
      "LGV+TI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:04<00:00, 30.56s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-TIFGSM: 81.0%\n",
      "LGV+TI+MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:04<00:00, 30.60s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Success rate of LGV-TIFGSM: 84.6%\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baselines\n",
    "\n",
    "We can now compare with the vanilla attacks, i.e., without LGV. A simple LGV+BIM attack beats all other attacks by a large margin. "
   ],
   "metadata": {
    "id": "J6bZcPCORfrB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"BIM\")\n",
    "atk = BIM(base_model, eps=4/255, alpha=4/255/10, steps=50)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"MI\")\n",
    "atk = MIFGSM(base_model, eps=4/255, alpha=4/255/10, steps=50)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"DI\")\n",
    "atk = DIFGSM(base_model, eps=4/255, alpha=4/255/10, steps=50)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"DI+MI\")\n",
    "atk = DIFGSM(base_model, eps=4/255, alpha=4/255/10, steps=50, decay=1.0)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"TI\")\n",
    "atk = TIFGSM(base_model, eps=4/255, alpha=4/255/10, steps=50)\n",
    "report_success_rate(atk)\n",
    "\n",
    "print(\"TI+MI\")\n",
    "atk = TIFGSM(base_model, eps=4/255, alpha=4/255/10, steps=50, decay=1.0)\n",
    "report_success_rate(atk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RD8S_aYRtZm",
    "outputId": "92cf16ae-0d85-49a7-bba9-dbd4b67b1eff"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BIM\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:03<00:00, 30.42s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of BIM: 72.6%\n",
      "\n",
      "MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.24s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of MIFGSM: 78.4%\n",
      "\n",
      "DI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.17s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of DIFGSM: 90.2%\n",
      "\n",
      "DI+MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:01<00:00, 30.19s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of DIFGSM: 94.2%\n",
      "\n",
      "TI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:05<00:00, 30.69s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of TIFGSM: 67.4%\n",
      "\n",
      "TI+MI\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8/8 [04:05<00:00, 30.66s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of TIFGSM: 74.4%\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Best**: Average LGV gradients \n",
    "\n",
    "Averaging the gradients of several models at every iteration is as easy as setting `n_grad` to a higher value than 1. It generally improves the attack, at the expense of increased computations and memory usage. `n_grad=-1` would compute every gradients on all available models (should be used for single-step attack like FGSM). A trade-off may be found with intermediate values such as `n_grad=10` in the following example."
   ],
   "metadata": {
    "id": "CDPHtnRzVN1i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# decrease batch-size\n",
    "testloader = torch.utils.data.DataLoader(testsubset, batch_size=8,\n",
    "                                         shuffle=False, num_workers=N_WORKERS,\n",
    "                                         pin_memory=False)\n",
    "\n",
    "# LGV + BIM with 10 averaged gradients per iteration \n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, \n",
    "          wd=1e-4, n_grad=10, attack_class=BIM, eps=4/255, alpha=4/255/10,\n",
    "          steps=50, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2M2n8tUZVPVV",
    "outputId": "6288595c-b91c-4fcb-9ef2-9f5d991b3bb3"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [44:47<00:00, 42.67s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of LGV-BIM: 99.2%\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best attack seems to be the combination of LGV with momentum on averaged gradients."
   ],
   "metadata": {
    "id": "vXpq_sUE3Jg9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"LGV+MI on 10 averaged gradients per iteration\")\n",
    "atk = LGV(base_model, trainloader, lr=0.05, epochs=10, nb_models_epoch=4, \n",
    "          wd=1e-4, n_grad=10, attack_class=MIFGSM, eps=4/255, alpha=4/255/10,\n",
    "          steps=50, verbose=False)\n",
    "atk.load_models(list_models)\n",
    "report_success_rate(atk)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqsmAyMS2YNO",
    "outputId": "7ee1e9c7-24b4-4895-9181-655c799a6ce2"
   },
   "execution_count": 43,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LGV+MI on 10 averaged gradients per iteration\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [44:45<00:00, 42.63s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Success rate of LGV-MIFGSM: 99.4%\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Credits\n",
    "\n",
    "This notebook was written by Martin Gubri. If you use this code in your research, please consider citing the LGV paper:\n",
    "\n",
    "```\n",
    "@inproceedings{,\n",
    "   abstract = {We propose transferability from Large Geometric Vicinity (LGV), a new technique to increase the transferability of black-box ad-versarial attacks. LGV starts from a pretrained surrogate model and collects multiple weight sets from a few additional training epochs with a constant and high learning rate. LGV exploits two geometric properties that we relate to transferability. First, models that belong to a wider weight optimum are better surrogates. Second, we identify a subspace able to generate an effective surrogate ensemble among this wider optimum. Through extensive experiments, we show that LGV alone outper-forms all (combinations of) four established test-time transformations by 1.8 to 59.9 percentage points. Our findings shed new light on the importance of the geometry of the weight space to explain the transferability of adversarial examples.},\n",
    "   author = {Martin Gubri and Maxime Cordy and Mike Papadakis and Yves Le Traon and Koushik Sen},\n",
    "   keywords = {Adversarial Examples,Deep Learning,Loss Geometry,Machine Learning Security,Transferability},\n",
    "   publisher = {ECCV 2022},\n",
    "   title = {LGV: Boosting Adversarial Example Transferability from Large Geometric Vicinity},\n",
    "   url = {https://github.com/Framartin/lgv-geometric-transferability},\n",
    "}\n",
    "```"
   ],
   "metadata": {
    "id": "ksHNlkMIK8Nb"
   }
  }
 ]
}